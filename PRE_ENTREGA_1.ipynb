{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlRL+IuicVOcjdocMiyfC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diaz-mateo/preenterga1ia/blob/main/PRE_ENTREGA_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzypjCDq_Gp_",
        "outputId": "06e689b5-0e4e-4c7d-bd77-9b3090d0a6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gpt4all) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gpt4all) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2024.12.14)\n",
            "Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.8.2\n",
            "--2025-02-02 18:47:31--  https://gpt4all.io/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf\n",
            "Resolving gpt4all.io (gpt4all.io)... 104.26.0.159, 104.26.1.159, 172.67.71.169, ...\n",
            "Connecting to gpt4all.io (gpt4all.io)|104.26.0.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-02-02 18:47:31 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Instalar la biblioteca gpt4all\n",
        "\n",
        "!pip install gpt4all\n",
        "\n",
        "# Descargar un modelo compatible\n",
        "\n",
        "!wget https://gpt4all.io/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf -O Meta-Llama-3-8B-Instruct.Q4_0.gguf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from gpt4all import GPT4All\n",
        "\n",
        "# Cargar el modelo\n",
        "modelo = \"Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n",
        "gpt4 = GPT4All(modelo)\n",
        "\n",
        "def generar_recomendaciones_json(prompt):\n",
        "    \"\"\"Genera recomendaciones en formato JSON utilizando GPT4All.\"\"\"\n",
        "    with gpt4.chat_session():\n",
        "        respuesta = gpt4.generate(prompt, max_tokens=512)\n",
        "    return respuesta\n",
        "\n",
        "def procesar_tarea_json(respuesta_json):\n",
        "    \"\"\"Procesa la respuesta JSON del modelo y extrae información clave.\"\"\"\n",
        "    try:\n",
        "        datos = json.loads(respuesta_json)\n",
        "        for serie in datos.get(\"recomendaciones\", []):\n",
        "            print(f\"\\nTítulo: {serie.get('título', 'Desconocido')}\")\n",
        "            print(f\"Descripción: {serie.get('descripción', 'Sin descripción')}\")\n",
        "            print(f\"Fecha: {serie.get('fecha', 'No disponible')}\")\n",
        "            print(f\"Elenco: {', '.join(serie.get('elenco', []))}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"\\nNo se pudo procesar la respuesta como JSON. Respuesta generada:\")\n",
        "        print(respuesta_json)\n",
        "\n",
        "def main():\n",
        "    # Solicitar la serie al usuario\n",
        "    serie_usuario = input(\"Introduce el nombre o descripción de una serie: \")\n",
        "\n",
        "    # Construir el prompt\n",
        "    prompt = f\"\"\"\n",
        "    Genera una lista de series similares a '{serie_usuario}' en formato JSON.\n",
        "    Estructura la respuesta así:\n",
        "    {{\n",
        "        \"recomendaciones\": [\n",
        "            {{\n",
        "                \"título\": \"Nombre de la serie\",\n",
        "                \"descripción\": \"Breve sinopsis\",\n",
        "                \"fecha\": \"Año de lanzamiento\",\n",
        "                \"elenco\": [\"Actor 1\", \"Actor 2\"]\n",
        "            }},\n",
        "            ...\n",
        "        ]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    # Generar y procesar la respuesta\n",
        "    respuesta = generar_recomendaciones_json(prompt)\n",
        "    procesar_tarea_json(respuesta)\n",
        "\n",
        "if __name__ == \"__main__\": # Changed _name_ to __name__\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBKTweUvBlc6",
        "outputId": "2ec25ca9-d8e0-44e1-a886-b3eb06e1d844"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce el nombre o descripción de una serie: Modern Family\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function LLModel._callback_decoder.<locals>._raw_callback at 0x7ec4002779c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gpt4all/_pyllmodel.py\", line 573, in _raw_callback\n",
            "    def _raw_callback(token_id: int, response: bytes) -> bool:\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No se pudo procesar la respuesta como JSON. Respuesta generada:\n",
            "Aquí te presento una lista de series similares a 'Modern Family' en formato JSON:\n",
            "\n",
            "{\n",
            "    \"recomendaciones\": [\n",
            "        {\n",
            "            \"título\": \"The Goldbergs\",\n",
            "            \"descripción\": \"Comedia que sigue la vida de un joven llamado Adam y su familia, inspirada en los años 80.\",\n",
            "            \"fecha\": \"2013-09-24\",\n",
            "            \"elenco\": [\"Wendi McLendon-Covey\", \"Jeff Garlin\"]\n",
            "        },\n",
            "        {\n",
            "            \"título\": \"The Middle\",\n",
            "            \"descripción\": \"Comedia que sigue la vida de una familia estadounidense en el corazón del país, con un estilo humorístico y realista.\",\n",
            "            \"fecha\": \"2009-09-30\",\n",
            "            \"elenco\": [\"Patricia Heaton\", \"Neil Flynn\"]\n",
            "        },\n",
            "        {\n",
            "            \"título\": \"Sub\n"
          ]
        }
      ]
    }
  ]
}